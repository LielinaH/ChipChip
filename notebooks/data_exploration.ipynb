{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categories:\n",
      "          column_name                    data_type\n",
      "0                  id                         uuid\n",
      "1              status                 USER-DEFINED\n",
      "2          created_at  timestamp without time zone\n",
      "3          updated_at  timestamp without time zone\n",
      "4          deleted_at  timestamp without time zone\n",
      "5          created_by                         uuid\n",
      "6                name            character varying\n",
      "7   short_description                         text\n",
      "8    long_description                         text\n",
      "9       detail_images                        ARRAY\n",
      "10      primary_image            character varying\n",
      "\n",
      "group_deals:\n",
      "               column_name                    data_type\n",
      "0                       id                         uuid\n",
      "1               product_id                         uuid\n",
      "2         max_group_member                      integer\n",
      "3              group_price                      numeric\n",
      "4               created_at  timestamp without time zone\n",
      "5               updated_at  timestamp without time zone\n",
      "6               deleted_at  timestamp without time zone\n",
      "7           effective_from  timestamp without time zone\n",
      "8             effective_to  timestamp without time zone\n",
      "9          expiration_time                      integer\n",
      "10  max_quantity_per_order                      integer\n",
      "11               lead_time            character varying\n",
      "12       reorder_wait_time            character varying\n",
      "\n",
      "groups:\n",
      "              column_name                    data_type\n",
      "0                      id                         uuid\n",
      "1          group_deals_id                         uuid\n",
      "2              created_by                         uuid\n",
      "3                  status                 USER-DEFINED\n",
      "4              created_at  timestamp without time zone\n",
      "5              updated_at  timestamp without time zone\n",
      "6              deleted_at  timestamp without time zone\n",
      "7  available_for_delivery                      boolean\n",
      "8           delivery_note            character varying\n",
      "\n",
      "groups_carts:\n",
      "  column_name                    data_type\n",
      "0          id                         uuid\n",
      "1    group_id                         uuid\n",
      "2     user_id                         uuid\n",
      "3    quantity                      integer\n",
      "4      status                 USER-DEFINED\n",
      "5  created_at  timestamp without time zone\n",
      "6  updated_at  timestamp without time zone\n",
      "7  deleted_at  timestamp without time zone\n",
      "\n",
      "orders:\n",
      "         column_name                    data_type\n",
      "0               meta                        jsonb\n",
      "1   personal_cart_id                         uuid\n",
      "2    groups_carts_id                         uuid\n",
      "3             status                 USER-DEFINED\n",
      "4       total_amount                      numeric\n",
      "5         created_at  timestamp without time zone\n",
      "6         updated_at  timestamp without time zone\n",
      "7         deleted_at  timestamp without time zone\n",
      "8        location_id                         uuid\n",
      "9           response                        jsonb\n",
      "10     discount_type                 USER-DEFINED\n",
      "11                id                         uuid\n",
      "12          discount                      numeric\n",
      "13    payment_method            character varying\n",
      "14  discount_rule_id            character varying\n",
      "\n",
      "product_names:\n",
      "      column_name                    data_type\n",
      "0              id                         uuid\n",
      "1      updated_at  timestamp without time zone\n",
      "2      deleted_at  timestamp without time zone\n",
      "3     category_id                         uuid\n",
      "4      created_by                         uuid\n",
      "5      created_at  timestamp without time zone\n",
      "6            name            character varying\n",
      "7  measuring_unit            character varying\n",
      "\n",
      "products:\n",
      "            column_name                    data_type\n",
      "0   stock_tracking_time  timestamp without time zone\n",
      "1             vendor_id                         uuid\n",
      "2              approved                 USER-DEFINED\n",
      "3           stock_alert                      integer\n",
      "4                weight                      numeric\n",
      "5     require_variation                      boolean\n",
      "6            commission                      numeric\n",
      "7                    id                         uuid\n",
      "8                status                 USER-DEFINED\n",
      "9            created_at  timestamp without time zone\n",
      "10           updated_at  timestamp without time zone\n",
      "11           deleted_at  timestamp without time zone\n",
      "12              name_id                         uuid\n",
      "13        sorting_level                      integer\n",
      "14    short_description            character varying\n",
      "15     long_description            character varying\n",
      "16        primary_image            character varying\n",
      "17        detail_images                        ARRAY\n",
      "18      explainer_video            character varying\n",
      "19                 tags                        ARRAY\n",
      "\n",
      "users:\n",
      "      column_name                    data_type\n",
      "0              id                         uuid\n",
      "1        password                        bytea\n",
      "2      country_id                         uuid\n",
      "3   user_birthday                         date\n",
      "4      created_at  timestamp without time zone\n",
      "5      updated_at  timestamp without time zone\n",
      "6      deleted_at  timestamp without time zone\n",
      "7     user_status                 USER-DEFINED\n",
      "8          gender            character varying\n",
      "9        share_by            character varying\n",
      "10     share_type            character varying\n",
      "11    share_value            character varying\n",
      "12          phone            character varying\n",
      "13          email            character varying\n",
      "14           name            character varying\n",
      "15    telegram_id            character varying\n",
      "16      last_name            character varying\n",
      "17  profile_image            character varying\n",
      "18      nick_name            character varying\n",
      "\n",
      "vendors:\n",
      "       column_name                    data_type\n",
      "0               id                         uuid\n",
      "1         location                        point\n",
      "2    registered_by                         uuid\n",
      "3       country_id                         uuid\n",
      "4           status                 USER-DEFINED\n",
      "5       created_at  timestamp without time zone\n",
      "6       updated_at  timestamp without time zone\n",
      "7       deleted_at  timestamp without time zone\n",
      "8             city            character varying\n",
      "9             logo            character varying\n",
      "10            name            character varying\n",
      "11           phone            character varying\n",
      "12         address            character varying\n",
      "13           email            character varying\n",
      "14  license_number            character varying\n",
      "15    house_number            character varying\n",
      "16     description            character varying\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Establish a connection to the PostgreSQL database using SQLAlchemy \n",
    "# This is the most important part the postgresql needs to be running and correctly configured\n",
    "# postgres is the username and password is password established and database is called name of the database.\n",
    "# my defualt port is 5432 but it can be different\n",
    "# again this is the most important part of the code\n",
    "engine = create_engine('postgresql+psycopg2://username:password@host:port/database')\n",
    "\n",
    "\n",
    "# List of specific tables to query\n",
    "specific_tables = [\n",
    "    'categories',\n",
    "    'group_deals',\n",
    "    'groups',\n",
    "    'groups_carts',\n",
    "    'orders',\n",
    "    'product_names',\n",
    "    'products',\n",
    "    'users',\n",
    "    'vendors'\n",
    "]\n",
    "\n",
    "# For each table, retrieve the columns\n",
    "for table in specific_tables:\n",
    "    query_columns = f\"\"\"\n",
    "    SELECT column_name, data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_name = '{table}';\n",
    "    \"\"\"\n",
    "    columns = pd.read_sql(query_columns, engine)\n",
    "    print(f\"\\n{table}:\")\n",
    "    print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "categories:\n",
      "                                     id       name short_description  \\\n",
      "0  af95ccc0-6ddb-4b10-82b2-4de8dabfcc46  Vegetable              desc   \n",
      "\n",
      "  long_description  status                                  primary_image  \\\n",
      "0             desc  ACTIVE  category/318486d9-c483-4b8b-88ce-1ef17978ff3f   \n",
      "\n",
      "                                       detail_images  \\\n",
      "0  [category/a7b3db05-0d38-4db7-9ee0-b10dfb446e6c...   \n",
      "\n",
      "                  created_at updated_at deleted_at  \\\n",
      "0 2023-10-12 10:00:38.345655       None       None   \n",
      "\n",
      "                             created_by  \n",
      "0  ad752023-a7af-4b14-95d0-6399f95c6eb6  \n",
      "\n",
      "group_deals:\n",
      "                                     id                            product_id  \\\n",
      "0  07d7d32e-ee7e-4594-8917-f604db617b4d  7af7c574-12e0-4d0e-a030-2721d28271a7   \n",
      "\n",
      "   max_group_member  group_price                 created_at updated_at  \\\n",
      "0                 3         67.0 2023-10-12 10:34:14.582614       None   \n",
      "\n",
      "                  deleted_at             effective_from  \\\n",
      "0 2023-10-12 11:05:43.512473 2023-10-12 10:34:14.582614   \n",
      "\n",
      "                effective_to  expiration_time max_quantity_per_order  \\\n",
      "0 2023-10-12 11:05:43.512473               24                   None   \n",
      "\n",
      "  lead_time reorder_wait_time  \n",
      "0      None              None  \n",
      "\n",
      "groups:\n",
      "                                     id                        group_deals_id  \\\n",
      "0  f1b11bbf-8cc8-4421-b573-887c35532a66  07d7d32e-ee7e-4594-8917-f604db617b4d   \n",
      "\n",
      "                             created_by   status                 created_at  \\\n",
      "0  ad752023-a7af-4b14-95d0-6399f95c6eb6  PENDING 2023-10-12 10:51:04.718603   \n",
      "\n",
      "                  updated_at deleted_at  available_for_delivery delivery_note  \n",
      "0 2023-10-12 10:51:04.718603       None                   False          None  \n",
      "\n",
      "groups_carts:\n",
      "                                     id                              group_id  \\\n",
      "0  32c07740-345f-4cfd-aca7-bfd58edb1fb7  e60d7466-d5f2-4ec0-a233-7cb517bc51b4   \n",
      "\n",
      "                                user_id  quantity     status  \\\n",
      "0  6f0097fd-f90e-47d9-87e6-12c7c86f6fd6         1  COMPLETED   \n",
      "\n",
      "                  created_at                 updated_at deleted_at  \n",
      "0 2023-10-12 12:25:24.589544 2023-10-12 12:27:58.139840       None  \n",
      "\n",
      "orders:\n",
      "                                     id personal_cart_id  \\\n",
      "0  349e932b-bf57-41b4-be2d-26c266ffeb1a             None   \n",
      "\n",
      "                        groups_carts_id    status  total_amount  \\\n",
      "0  e917fa7d-17eb-4be4-a54e-216ddbdef68b  CANCELED        422.75   \n",
      "\n",
      "                  created_at                 updated_at  \\\n",
      "0 2023-12-30 11:25:54.869678 2023-12-30 11:25:54.869678   \n",
      "\n",
      "                  deleted_at                           location_id response  \\\n",
      "0 2023-12-30 11:27:42.577066  168a0e9a-32bc-4111-8ed1-28e6bba5603f     None   \n",
      "\n",
      "  payment_method  discount discount_type discount_rule_id  meta  \n",
      "0          CHAPA      0.05          None             None  None  \n",
      "\n",
      "product_names:\n",
      "                                     id         name  \\\n",
      "0  9215866f-2c88-440a-8d2a-26f121041be2  Mawel pasta   \n",
      "\n",
      "                            category_id                            created_by  \\\n",
      "0  9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed  e485817f-6d13-4a80-9112-86cd4a2eabff   \n",
      "\n",
      "                  created_at updated_at deleted_at measuring_unit  \n",
      "0 2024-06-26 07:10:43.616821       None       None          piece  \n",
      "\n",
      "products:\n",
      "                                     id                             vendor_id  \\\n",
      "0  09d44732-6be6-4e44-bef3-dfd73f03c3db  c0cd08f9-543f-4e22-9284-aa3836d7dbc0   \n",
      "\n",
      "                                   short_description  \\\n",
      "0  Mango, known for its tropical sweetness, is a ...   \n",
      "\n",
      "                                    long_description  \\\n",
      "0  Mango, known for its tropical sweetness, is a ...   \n",
      "\n",
      "                                      primary_image  \\\n",
      "0  product/287e1409-1749-4e99-802b-e1082022e0fc.jpg   \n",
      "\n",
      "                                       detail_images    status tags  \\\n",
      "0  [product/ff28cc2f-ff73-48b1-afa6-51d73b7efdfa....  INACTIVE   []   \n",
      "\n",
      "                  created_at                 updated_at deleted_at  \\\n",
      "0 2024-07-16 22:14:46.594736 2024-08-07 13:22:16.064561       None   \n",
      "\n",
      "                                name_id  sorting_level  approved  stock_alert  \\\n",
      "0  f119e3cc-1b27-49f3-b34c-dfb1b3e8616f              6  APPROVED            5   \n",
      "\n",
      "  weight  require_variation explainer_video  commission stock_tracking_time  \n",
      "0   None              False            None         0.0                None  \n",
      "\n",
      "users:\n",
      "                                     id           phone  \\\n",
      "0  daabf237-7f7a-4af2-9c22-058d851aad80  +251daabf237-7   \n",
      "\n",
      "                                               email  \\\n",
      "0  userdaabf237-7f7a-4af2-9c22-058d851aad80@examp...   \n",
      "\n",
      "                                            password  \\\n",
      "0  [b'$', b'2', b'a', b'$', b'1', b'4', b'$', b'G...   \n",
      "\n",
      "                             country_id user_birthday  \\\n",
      "0  4391b559-957b-4d6f-854b-3817aaa6f6e0          None   \n",
      "\n",
      "                                       profile_image nick_name gender  \\\n",
      "0  https://stagingchipchip.fra1.digitaloceanspace...      None   None   \n",
      "\n",
      "                  created_at updated_at deleted_at    name user_status  \\\n",
      "0 2024-10-24 11:04:12.175700       None       None  Abrish    VERIFIED   \n",
      "\n",
      "  last_name share_by share_type share_value telegram_id  \n",
      "0      None     None       None        None        None  \n",
      "\n",
      "vendors:\n",
      "                                     id     name           phone      address  \\\n",
      "0  2b0a7e3e-3cc3-4cd0-8ba2-ebe31eeae50e  unknown  +2512b0a7e3e-3  Addis Ababa   \n",
      "\n",
      "  location license_number   house_number  \\\n",
      "0    (0,0)  new2b0a7e3e-3  new2b0a7e3e-3   \n",
      "\n",
      "                          registered_by         city  logo email description  \\\n",
      "0  e485817f-6d13-4a80-9112-86cd4a2eabff  Addis ababa  None  None        None   \n",
      "\n",
      "                             country_id  status                 created_at  \\\n",
      "0  4391b559-957b-4d6f-854b-3817aaa6f6e0  ACTIVE 2024-06-11 10:35:20.375214   \n",
      "\n",
      "                  updated_at deleted_at  \n",
      "0 2024-06-11 10:35:20.375214       None  \n"
     ]
    }
   ],
   "source": [
    "# Query to show top 1 row for each table in specific_tables and show it\n",
    "for table in specific_tables:\n",
    "    query_data = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {table}\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    data = pd.read_sql(query_data, engine)\n",
    "    print(f\"\\n{table}:\")\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Database and Data Understanding\n",
    "\n",
    "## 1. Complex Querying\n",
    "\n",
    "### 1.1.1 Write a SQL query to fetch the top 10 users who contributed the highest revenue within the last 30 days, along with the number of groups they participated in and the categories of products they purchased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "WITH date_30_days_ago AS (\n",
    "    SELECT MAX(created_at) - INTERVAL '30 days' AS date_30_days_ago\n",
    "    FROM orders\n",
    "),\n",
    "filtered_orders AS (\n",
    "    SELECT o.*, gc.user_id, g.group_deals_id, gd.product_id\n",
    "    FROM orders o\n",
    "    JOIN groups_carts gc ON o.groups_carts_id = gc.id\n",
    "    JOIN groups g ON gc.group_id = g.id\n",
    "    JOIN group_deals gd ON g.group_deals_id = gd.id\n",
    "    WHERE o.created_at >= (SELECT date_30_days_ago FROM date_30_days_ago)\n",
    "      AND o.status = 'COMPLETED' -- Include only completed orders\n",
    "),\n",
    "user_revenue AS (\n",
    "    SELECT \n",
    "        fo.user_id, \n",
    "        SUM(fo.total_amount) AS total_revenue\n",
    "    FROM filtered_orders fo\n",
    "    GROUP BY fo.user_id\n",
    "),\n",
    "user_group_count AS (\n",
    "    SELECT \n",
    "        gc.user_id, \n",
    "        COUNT(DISTINCT gc.group_id) AS group_count\n",
    "    FROM groups_carts gc\n",
    "    JOIN filtered_orders fo ON gc.id = fo.groups_carts_id\n",
    "    GROUP BY gc.user_id\n",
    "),\n",
    "user_product_categories AS (\n",
    "    SELECT \n",
    "        fo.user_id, \n",
    "        ARRAY_AGG(DISTINCT pn.category_id) AS purchased_categories\n",
    "    FROM filtered_orders fo\n",
    "    JOIN products p ON fo.product_id = p.id\n",
    "    JOIN product_names pn ON p.name_id = pn.id\n",
    "    GROUP BY fo.user_id\n",
    ")\n",
    "SELECT \n",
    "    u.id AS user_id,\n",
    "    u.name AS user_name,\n",
    "    COALESCE(ur.total_revenue, 0) AS total_revenue,\n",
    "    COALESCE(ugc.group_count, 0) AS group_count,\n",
    "    COALESCE(upc.purchased_categories, ARRAY[]::uuid[]) AS purchased_categories\n",
    "FROM users u\n",
    "LEFT JOIN user_revenue ur ON u.id = ur.user_id\n",
    "LEFT JOIN user_group_count ugc ON u.id = ugc.user_id\n",
    "LEFT JOIN user_product_categories upc ON u.id = upc.user_id\n",
    "ORDER BY total_revenue DESC\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Top 10 Users by Revenue\n",
    "\n",
    "The following table lists the top 10 users who contributed the highest revenue within the last 30 days, along with the number of groups they participated in and the categories of products they purchased.\n",
    "\n",
    "| user_id                               | user_name | total_revenue | group_count | purchased_categories                                                                                           |\n",
    "|---------------------------------------|-----------|---------------|-------------|---------------------------------------------------------------------------------------------------------------|\n",
    "| 02afef07-11f8-4a29-848a-ebae8c3dd783  | Nahom     | 22107.60      | 79          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,d24dd74f-bb40-49bc-a19c-f9e90d77f4ea,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| cdb909c0-8549-4c1a-9345-8a6c22e09dc8  | Dero      | 21982.00      | 68          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,d24dd74f-bb40-49bc-a19c-f9e90d77f4ea,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| a69c75d9-31d2-49fc-98a3-93d937bb011f  | fikadu    | 18405.00      | 72          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,d24dd74f-bb40-49bc-a19c-f9e90d77f4ea,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| d25a7eb5-3e7d-40d2-bc30-e370111e79f1  | Tsion     | 13338.00      | 47          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| afdd0def-726e-41ed-b156-563647a629d0  | Solomon   | 12280.00      | 33          | 036ac34e-2d13-4a7e-a941-897b032e9c39,33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6f1ecaa5-fac0-4111-ac77-a717940c788d,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| ef7c0d65-1619-4685-8527-3b65a194bfd6  | Etalem    | 11996.00      | 46          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| 702ee90d-51ac-48c8-9dba-38f0dcb32c61  | ashu      | 10624.00      | 56          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,d24dd74f-bb40-49bc-a19c-f9e90d77f4ea,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| 3cb765d7-76b5-47a8-9634-42f8181baa03  | Mickey    | 10533.60      | 31          | 036ac34e-2d13-4a7e-a941-897b032e9c39,33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6f1ecaa5-fac0-4111-ac77-a717940c788d,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46 |\n",
    "| e1e1ef41-fce1-4fdd-a1b2-1326bd373fe3  | Belsti    | 9652.00       | 25          | 036ac34e-2d13-4a7e-a941-897b032e9c39,33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6f1ecaa5-fac0-4111-ac77-a717940c788d,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,ed470df7-f8ae-4d26-8865-7241f085785b |\n",
    "| 39df2681-cc46-43ca-acd7-33994caf06c3  | lemlem    | 8536.00       | 44          | 33cd8255-6371-4baf-9888-555973935748,4f78f76d-ab7e-4553-9535-93b113150f20,6fe71c72-7796-466a-acbf-aa1c93f1a123,9a00a819-d1f5-49a3-85b6-b1d9a97ef9ed,af95ccc0-6ddb-4b10-82b2-4de8dabfcc46,d24dd74f-bb40-49bc-a19c-f9e90d77f4ea |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Generate a query to calculate the conversion rate for group deals, defined as the ratio of completed orders (status = 'completed') to all group deals created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "WITH completed_orders_count AS (\n",
    "    SELECT \n",
    "        gd.id AS group_deals_id,\n",
    "        COUNT(o.id) AS completed_orders\n",
    "    FROM group_deals gd\n",
    "    LEFT JOIN groups g ON gd.id = g.group_deals_id\n",
    "    LEFT JOIN groups_carts gc ON g.id = gc.group_id\n",
    "    LEFT JOIN orders o ON gc.id = o.groups_carts_id\n",
    "    WHERE o.status = 'COMPLETED' -- Only count completed orders\n",
    "    GROUP BY gd.id\n",
    "),\n",
    "total_group_deals AS (\n",
    "    SELECT \n",
    "        COUNT(*) AS total_group_deals\n",
    "    FROM group_deals\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(SUM(coc.completed_orders), 0) AS total_completed_orders,\n",
    "    (SELECT total_group_deals FROM total_group_deals) AS total_group_deals,\n",
    "    COALESCE(SUM(coc.completed_orders), 0) * 1.0 / NULLIF((SELECT total_group_deals FROM total_group_deals), 0) AS conversion_rate\n",
    "FROM completed_orders_count coc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Conversion Rate Analysis\n",
    "\n",
    "The conversion rate for group deals is calculated as the ratio of completed orders to all group deals created. The following metrics are derived from the analysis above:\n",
    "\n",
    "- **Total Completed Orders:** 292,279\n",
    "- **Total Group Deals:** 3,603\n",
    "- **Conversion Rate:** 81.12%\n",
    "\n",
    "These metrics provide insights into the effectiveness of group deals in converting potential customers into actual buyers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Data Processing\n",
    "\n",
    "## 2.2 Advanced Data Aggregation\n",
    "\n",
    "A script that fetches data from the database to calculate a monthly cohort analysis of users, grouping them by their signup month (`created_at`) and showing retention percentages based on their group deal participation over the next 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>month_diff</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signup_month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-10</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>70.83%</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>47.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>33.98%</td>\n",
       "      <td>22.79%</td>\n",
       "      <td>17.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>53.8%</td>\n",
       "      <td>45.76%</td>\n",
       "      <td>46.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>50.45%</td>\n",
       "      <td>46.33%</td>\n",
       "      <td>50.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-02</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>59.68%</td>\n",
       "      <td>58.56%</td>\n",
       "      <td>49.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>46.91%</td>\n",
       "      <td>32.92%</td>\n",
       "      <td>34.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>30.18%</td>\n",
       "      <td>23.95%</td>\n",
       "      <td>17.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>25.89%</td>\n",
       "      <td>14.27%</td>\n",
       "      <td>14.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>26.17%</td>\n",
       "      <td>21.74%</td>\n",
       "      <td>16.74%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>34.05%</td>\n",
       "      <td>21.89%</td>\n",
       "      <td>13.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>37.8%</td>\n",
       "      <td>22.85%</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>36.46%</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10</th>\n",
       "      <td>100.0%</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "month_diff         0       1       2       3\n",
       "signup_month                                \n",
       "2023-10       100.0%  70.83%   50.0%  47.92%\n",
       "2023-11       100.0%  33.98%  22.79%  17.76%\n",
       "2023-12       100.0%   53.8%  45.76%  46.53%\n",
       "2024-01       100.0%  50.45%  46.33%  50.99%\n",
       "2024-02       100.0%  59.68%  58.56%  49.76%\n",
       "2024-03       100.0%  46.91%  32.92%  34.23%\n",
       "2024-04       100.0%  30.18%  23.95%  17.18%\n",
       "2024-05       100.0%  25.89%  14.27%   14.7%\n",
       "2024-06       100.0%  26.17%  21.74%  16.74%\n",
       "2024-07       100.0%  34.05%  21.89%  13.88%\n",
       "2024-08       100.0%   37.8%  22.85%     nan\n",
       "2024-09       100.0%  36.46%     nan     nan\n",
       "2024-10       100.0%     nan     nan     nan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Fetch data from the database\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    u.id AS user_id,\n",
    "    u.created_at AS signup_date,\n",
    "    g.created_at AS group_deal_date\n",
    "FROM users u\n",
    "LEFT JOIN groups_carts gc ON u.id = gc.user_id\n",
    "LEFT JOIN groups g ON gc.group_id = g.id\n",
    "WHERE u.created_at IS NOT NULL\n",
    "  AND g.created_at IS NOT NULL\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['signup_date'] = pd.to_datetime(df['signup_date'])\n",
    "df['group_deal_date'] = pd.to_datetime(df['group_deal_date'])\n",
    "\n",
    "# Extract year and month for cohort analysis\n",
    "df['signup_month'] = df['signup_date'].dt.to_period('M')\n",
    "df['group_deal_month'] = df['group_deal_date'].dt.to_period('M')\n",
    "\n",
    "# Calculate the month difference between signup and group deal participation\n",
    "df['month_diff'] = (df['group_deal_date'].dt.year - df['signup_date'].dt.year) * 12 + (df['group_deal_date'].dt.month - df['signup_date'].dt.month)\n",
    "\n",
    "# Filter data for the first 3 months after signup and ensure no negative values\n",
    "df = df[(df['month_diff'] >= 0) & (df['month_diff'] <= 3)]\n",
    "\n",
    "# Create a cohort table\n",
    "cohort_data = df.groupby(['signup_month', 'month_diff']).agg({'user_id': 'nunique'}).reset_index()\n",
    "\n",
    "# Pivot the cohort table\n",
    "cohort_pivot = cohort_data.pivot_table(index='signup_month', columns='month_diff', values='user_id')\n",
    "\n",
    "# Calculate retention percentages\n",
    "cohort_size = cohort_pivot.iloc[:, 0]\n",
    "retention_table = cohort_pivot.divide(cohort_size, axis=0) * 100\n",
    "retention_table = retention_table.round(2)\n",
    "retention_table = pd.DataFrame(retention_table)\n",
    "retention_table = retention_table.map(lambda x: f\"{x}%\" if pd.notna(x) else \"nan\")\n",
    "retention_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cohort Analysis\n",
    "\n",
    "The cohort analysis below shows the retention rates of users based on their signup month. The retention rate is calculated as the percentage of users who participated in group deals in the subsequent months after their signup.\n",
    "\n",
    "| signup_month | 0       | 1       | 2       | 3       |\n",
    "|--------------|---------|---------|---------|---------|\n",
    "| 2023-10      | 100.0%  | 70.83%  | 50.0%   | 47.92%  |\n",
    "| 2023-11      | 100.0%  | 33.98%  | 22.79%  | 17.76%  |\n",
    "| 2023-12      | 100.0%  | 53.8%   | 45.76%  | 46.53%  |\n",
    "| 2024-01      | 100.0%  | 50.45%  | 46.33%  | 50.99%  |\n",
    "| 2024-02      | 100.0%  | 59.68%  | 58.56%  | 49.76%  |\n",
    "| 2024-03      | 100.0%  | 46.91%  | 32.92%  | 34.23%  |\n",
    "| 2024-04      | 100.0%  | 30.18%  | 23.95%  | 17.18%  |\n",
    "| 2024-05      | 100.0%  | 25.89%  | 14.27%  | 14.7%   |\n",
    "| 2024-06      | 100.0%  | 26.17%  | 21.74%  | 16.74%  |\n",
    "| 2024-07      | 100.0%  | 34.05%  | 21.89%  | 13.88%  |\n",
    "| 2024-08      | 100.0%  | 37.8%   | 22.85%  | nan     |\n",
    "| 2024-09      | 100.0%  | 36.46%  | nan     | nan     |\n",
    "| 2024-10      | 100.0%  | nan     | nan     | nan     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Dynamic Data Preparation\n",
    "### 2.3.1. A Function to Dynamically Fetch the Most Popular Product Categories and Calculate Their Sales Growth Percentage\n",
    "\n",
    "This function dynamically fetches the most popular product categories from the database and calculates their sales growth percentage compared to the previous period (weekly or monthly). The function performs the following steps:\n",
    "\n",
    "1. **Database Connection:** Establishes a connection to the PostgreSQL database using SQLAlchemy.\n",
    "2. **Fetch Sales Data:** Retrieves sales data by joining necessary tables in the database.\n",
    "3. **Ensure Date Format:** Ensures the date column is in datetime format for accurate calculations.\n",
    "4. **Determine Date Ranges:** Determines the date ranges for the current and previous periods based on the specified aggregation period (weekly or monthly).\n",
    "5. **Filter Data:** Filters the sales data for the current and previous periods.\n",
    "6. **Aggregate Sales:** Aggregates sales by category for both the current and previous periods.\n",
    "7. **Merge Sales Data:** Merges the sales data from the two periods.\n",
    "8. **Calculate Growth Percentage:** Calculates the sales growth percentage for each category.\n",
    "9. **Handle NaN and Inf Values:** Replaces NaN and Inf growth values with 0 for categories with no previous sales.\n",
    "10. **Sort and Select Top Categories:** Sorts the categories by current sales and selects the top categories based on the specified number.\n",
    "\n",
    "The function returns a DataFrame containing the category, current sales, previous sales, and growth percentage for the top product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>current_sales</th>\n",
       "      <th>previous_sales</th>\n",
       "      <th>growth_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vegetable</td>\n",
       "      <td>1793329.00</td>\n",
       "      <td>2429761.00</td>\n",
       "      <td>-26.193193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fruit</td>\n",
       "      <td>930411.00</td>\n",
       "      <td>874894.00</td>\n",
       "      <td>6.345569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Packed Food &amp; Drink</td>\n",
       "      <td>187159.25</td>\n",
       "      <td>187761.90</td>\n",
       "      <td>-0.320965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condiments</td>\n",
       "      <td>123603.00</td>\n",
       "      <td>188187.00</td>\n",
       "      <td>-34.319055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>115700.00</td>\n",
       "      <td>100122.00</td>\n",
       "      <td>15.559018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Meat and Poultry</td>\n",
       "      <td>64776.00</td>\n",
       "      <td>86776.00</td>\n",
       "      <td>-25.352632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Personal Care</td>\n",
       "      <td>62010.40</td>\n",
       "      <td>36971.35</td>\n",
       "      <td>67.725550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Household</td>\n",
       "      <td>18738.00</td>\n",
       "      <td>17782.30</td>\n",
       "      <td>5.374445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cloth &amp; Fashion</td>\n",
       "      <td>17013.00</td>\n",
       "      <td>38243.00</td>\n",
       "      <td>-55.513427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dairy</td>\n",
       "      <td>15135.00</td>\n",
       "      <td>44578.00</td>\n",
       "      <td>-66.048275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Holiday</td>\n",
       "      <td>12915.00</td>\n",
       "      <td>19674.00</td>\n",
       "      <td>-34.354986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baby Items</td>\n",
       "      <td>5214.00</td>\n",
       "      <td>5790.00</td>\n",
       "      <td>-9.948187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category  current_sales  previous_sales  growth_percentage\n",
       "11            Vegetable     1793329.00      2429761.00         -26.193193\n",
       "5                 Fruit      930411.00       874894.00           6.345569\n",
       "9   Packed Food & Drink      187159.25       187761.90          -0.320965\n",
       "3           Condiments       123603.00       188187.00         -34.319055\n",
       "1          Baking Goods      115700.00       100122.00          15.559018\n",
       "8      Meat and Poultry       64776.00        86776.00         -25.352632\n",
       "10        Personal Care       62010.40        36971.35          67.725550\n",
       "7             Household       18738.00        17782.30           5.374445\n",
       "2       Cloth & Fashion       17013.00        38243.00         -55.513427\n",
       "4                 Dairy       15135.00        44578.00         -66.048275\n",
       "6               Holiday       12915.00        19674.00         -34.354986\n",
       "0            Baby Items        5214.00         5790.00          -9.948187"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetch_sales_data(engine):\n",
    "    \"\"\"\n",
    "    Fetch sales data from the database by joining necessary tables.\n",
    "\n",
    "    Args:\n",
    "        engine: SQLAlchemy engine object.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing sales data.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        o.created_at AS order_date,\n",
    "        c.name AS category,\n",
    "        o.total_amount AS sales\n",
    "    FROM orders o\n",
    "    JOIN groups_carts gc ON o.groups_carts_id = gc.id\n",
    "    JOIN groups g ON gc.group_id = g.id\n",
    "    JOIN group_deals gd ON g.group_deals_id = gd.id\n",
    "    JOIN products p ON gd.product_id = p.id\n",
    "    JOIN product_names pn ON p.name_id = pn.id\n",
    "    JOIN categories c ON pn.category_id = c.id\n",
    "    WHERE o.status = 'COMPLETED'\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    return df\n",
    "\n",
    "def calculate_sales_growth(data, date_column, category_column, sales_column, period='weekly'):\n",
    "    \"\"\"\n",
    "    Calculate sales growth percentage for the most popular product categories.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame containing sales data.\n",
    "        date_column (str): Column name for the order date.\n",
    "        category_column (str): Column name for the product category.\n",
    "        sales_column (str): Column name for the sales amount.\n",
    "        period (str): Aggregation period ('weekly' or 'monthly'). Default is 'weekly'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with category, current sales, previous sales, and growth percentage.\n",
    "    \"\"\"\n",
    "    # Ensure the date column is in datetime format\n",
    "    data[date_column] = pd.to_datetime(data[date_column])\n",
    "\n",
    "    # Determine date ranges for current and previous periods\n",
    "    latest_date = data[date_column].max()\n",
    "\n",
    "    if period == 'weekly':\n",
    "        current_start = latest_date - pd.Timedelta(days=7)\n",
    "        previous_start = current_start - pd.Timedelta(days=7)\n",
    "        previous_end = current_start\n",
    "    elif period == 'monthly':\n",
    "        current_start = latest_date - pd.DateOffset(months=1)\n",
    "        previous_start = current_start - pd.DateOffset(months=1)\n",
    "        previous_end = current_start\n",
    "    else:\n",
    "        raise ValueError(\"Invalid period. Use 'weekly' or 'monthly'.\")\n",
    "\n",
    "    # Filter data for the current and previous periods\n",
    "    current_data = data[(data[date_column] > current_start)]\n",
    "    previous_data = data[(data[date_column] > previous_start) & (data[date_column] <= previous_end)]\n",
    "\n",
    "    # Aggregate sales by category for both periods\n",
    "    current_sales = current_data.groupby(category_column)[sales_column].sum().reset_index()\n",
    "    current_sales.rename(columns={sales_column: 'current_sales'}, inplace=True)\n",
    "\n",
    "    previous_sales = previous_data.groupby(category_column)[sales_column].sum().reset_index()\n",
    "    previous_sales.rename(columns={sales_column: 'previous_sales'}, inplace=True)\n",
    "\n",
    "    # Merge the two periods' sales data\n",
    "    sales_comparison = pd.merge(current_sales, previous_sales, on=category_column, how='outer').fillna(0)\n",
    "\n",
    "    # Calculate growth percentage\n",
    "    sales_comparison['growth_percentage'] = (\n",
    "        (sales_comparison['current_sales'] - sales_comparison['previous_sales']) / \n",
    "        sales_comparison['previous_sales'].replace(0, float('nan'))\n",
    "    ) * 100\n",
    "\n",
    "    # Replace NaN and Inf growth values with 0 (for categories with no previous sales)\n",
    "    sales_comparison['growth_percentage'] = sales_comparison['growth_percentage'].fillna(0).replace(float('inf'), 0)\n",
    "\n",
    "    # Sort by current sales\n",
    "    sorted_categories = sales_comparison.sort_values(by='current_sales', ascending=False)\n",
    "\n",
    "    return sorted_categories\n",
    "\n",
    "# Fetch sales data from the database\n",
    "sales_data = fetch_sales_data(engine)\n",
    "\n",
    "# Calculate sales growth\n",
    "result = calculate_sales_growth(\n",
    "    data=sales_data,\n",
    "    date_column='order_date',\n",
    "    category_column='category',\n",
    "    sales_column='sales',\n",
    "    period='monthly' # options are 'weekly' or 'monthly'\n",
    ")\n",
    "\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Sales Growth Analysis\n",
    "\n",
    "The table below shows the sales growth percentage for the most popular product categories. The growth percentage is calculated by comparing the current sales to the previous sales.\n",
    "\n",
    "| Category              | Current Sales | Previous Sales | Growth Percentage |\n",
    "|-----------------------|---------------|----------------|-------------------|\n",
    "| Vegetable             | 1,793,329.00  | 2,429,761.00   | -26.19%           |\n",
    "| Fruit                 | 930,411.00    | 874,894.00     | 6.35%             |\n",
    "| Packed Food & Drink   | 187,159.25    | 187,761.90     | -0.32%            |\n",
    "| Condiments            | 123,603.00    | 188,187.00     | -34.32%           |\n",
    "| Baking Goods          | 115,700.00    | 100,122.00     | 15.56%            |\n",
    "| Meat and Poultry      | 64,776.00     | 86,776.00      | -25.35%           |\n",
    "| Personal Care         | 62,010.40     | 36,971.35      | 67.73%            |\n",
    "| Household             | 18,738.00     | 17,782.30      | 5.37%             |\n",
    "| Cloth & Fashion       | 17,013.00     | 38,243.00      | -55.51%           |\n",
    "| Dairy                 | 15,135.00     | 44,578.00      | -66.05%           |\n",
    "| Holiday               | 12,915.00     | 19,674.00      | -34.35%           |\n",
    "| Baby Items            | 5,214.00      | 5,790.00       | -9.95%            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Data Preprocessing Class\n",
    "\n",
    "\n",
    "This class provides a reusable Python implementation to preprocess and normalize data for various tables. The class performs the following steps:\n",
    "\n",
    "1. **Database Connection:** Establishes a connection to the PostgreSQL database using SQLAlchemy.\n",
    "2. **Load Data:** Loads data from the specified table in the database.\n",
    "3. **Handle NULL Values:** Handles NULL values using the specified strategy (mean, median, mode, or constant).\n",
    "4. **Encode Categorical Variables:** Encodes categorical variables using one-hot encoding or label encoding.\n",
    "5. **Aggregate Timestamps:** Aggregates timestamps to specified periods (daily, weekly, monthly, or yearly).\n",
    "6. **Preprocess Data:** Combines all preprocessing steps into a single method to preprocess and normalize data for a specific table.\n",
    "\n",
    "The class returns a DataFrame containing the preprocessed data.\n",
    "(e.g., handling NULLs, encoding categorical variables, aggregating timestamps to periods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          id personal_cart_id  \\\n",
      "0       349e932b-bf57-41b4-be2d-26c266ffeb1a             None   \n",
      "1       0badd3d4-b4bd-4256-9189-b1f5a1eb033a             None   \n",
      "2       ca0a288f-85eb-485d-b494-2c26b3ce23ff             None   \n",
      "3       b3b3843f-cacd-4d24-a9b0-4220a11cf08b             None   \n",
      "4       8bf85ebd-e96b-4409-b01a-b3a22cc2894e             None   \n",
      "...                                      ...              ...   \n",
      "377911  83a07166-f19d-4645-8764-04a669f54eef             None   \n",
      "377912  bf578f5a-6770-4468-b42a-fec5d510dcd9             None   \n",
      "377913  94785d86-f0a0-4308-aa74-a63166e682a3             None   \n",
      "377914  092e7913-5ae8-4c85-b3fa-fb5d28062f64             None   \n",
      "377915  46ea272a-e940-438d-a38c-e5ee2212212b             None   \n",
      "\n",
      "                             groups_carts_id  total_amount  \\\n",
      "0       e917fa7d-17eb-4be4-a54e-216ddbdef68b        422.75   \n",
      "1       48ae0049-dabc-4631-a670-6df813b0f431        750.50   \n",
      "2       3c933d2c-04ef-466f-b797-11679951c994         84.55   \n",
      "3       da6bf7ef-382f-42a4-8e9d-c8a3487542ab         15.20   \n",
      "4       d399dba5-a9d4-43a0-a1bb-f602646a9eea         15.20   \n",
      "...                                      ...           ...   \n",
      "377911  6c81939b-ec9b-480c-b953-65d32099b655         80.00   \n",
      "377912  f32c6283-9682-4aaf-82ed-b88547eb1995        176.00   \n",
      "377913  97444842-e3aa-4331-b106-ae7d7a7273f7         29.00   \n",
      "377914  eb0061b3-2924-47bb-a13d-6be91b939397        138.00   \n",
      "377915  3c64a0d3-c4b3-4206-b0c5-f2ec5e503089         29.00   \n",
      "\n",
      "                       created_at                 updated_at  \\\n",
      "0      2023-12-30 11:25:54.869678 2023-12-30 11:25:54.869678   \n",
      "1      2024-02-10 15:16:51.545295 2024-02-10 15:16:51.545295   \n",
      "2      2023-12-30 12:41:46.442494 2023-12-30 12:41:46.442494   \n",
      "3      2023-12-30 15:13:44.682047 2023-12-30 15:13:44.682047   \n",
      "4      2023-12-30 15:54:31.320694 2023-12-30 15:54:31.320694   \n",
      "...                           ...                        ...   \n",
      "377911 2024-10-07 04:35:52.358160 2024-10-07 04:36:34.199554   \n",
      "377912 2024-10-07 04:37:40.608413 2024-10-07 04:38:13.283700   \n",
      "377913 2024-10-07 04:45:55.749437 2024-10-07 04:46:57.716902   \n",
      "377914 2024-10-07 04:49:30.703202 2024-10-07 04:49:31.757484   \n",
      "377915 2024-10-07 04:54:12.421855 2024-10-07 04:56:00.184353   \n",
      "\n",
      "                       deleted_at                           location_id  \\\n",
      "0      2023-12-30 11:27:42.577066  168a0e9a-32bc-4111-8ed1-28e6bba5603f   \n",
      "1                             NaT  6b1e6e1f-73be-4ea6-84ef-f2d55ed69240   \n",
      "2      2023-12-30 13:00:37.982030  b7c4ea64-14d6-4dfd-80fd-0b52c998b6c1   \n",
      "3                             NaT  dbc01ccd-ac37-44b1-b618-b40af8f33da8   \n",
      "4      2023-12-30 15:54:50.814038  640f3834-2e18-4e9b-b311-2aec7a3fd6e2   \n",
      "...                           ...                                   ...   \n",
      "377911                        NaT  e092b8bd-475a-4507-a984-0b6393fda620   \n",
      "377912                        NaT  e092b8bd-475a-4507-a984-0b6393fda620   \n",
      "377913                        NaT  8ec75fd6-f2b9-4c14-9f43-0d0cfdfa5560   \n",
      "377914                        NaT  154d602f-af6c-4b8e-932b-055d5851f4ad   \n",
      "377915                        NaT  8ec75fd6-f2b9-4c14-9f43-0d0cfdfa5560   \n",
      "\n",
      "       response  discount  ... status_CANCELED status_COMPLETED status_FAILED  \\\n",
      "0          None      0.05  ...            True            False         False   \n",
      "1          None      0.05  ...           False            False         False   \n",
      "2          None      0.05  ...            True            False         False   \n",
      "3          None      0.05  ...           False            False         False   \n",
      "4          None      0.05  ...            True            False         False   \n",
      "...         ...       ...  ...             ...              ...           ...   \n",
      "377911     None      0.00  ...           False             True         False   \n",
      "377912     None      0.00  ...           False             True         False   \n",
      "377913     None      0.00  ...           False             True         False   \n",
      "377914     None      0.00  ...           False             True         False   \n",
      "377915     None      0.00  ...           False             True         False   \n",
      "\n",
      "        status_PENDING  payment_method_CASH_ON_DELIVERY  payment_method_CHAPA  \\\n",
      "0                False                            False                  True   \n",
      "1                 True                            False                  True   \n",
      "2                False                            False                  True   \n",
      "3                 True                            False                  True   \n",
      "4                False                            False                  True   \n",
      "...                ...                              ...                   ...   \n",
      "377911           False                            False                 False   \n",
      "377912           False                            False                 False   \n",
      "377913           False                            False                 False   \n",
      "377914           False                            False                 False   \n",
      "377915           False                            False                 False   \n",
      "\n",
      "        payment_method_CHIPCHIP_PAY  payment_method_CHIPCHIP_WALLET  \\\n",
      "0                             False                           False   \n",
      "1                             False                           False   \n",
      "2                             False                           False   \n",
      "3                             False                           False   \n",
      "4                             False                           False   \n",
      "...                             ...                             ...   \n",
      "377911                         True                           False   \n",
      "377912                         True                           False   \n",
      "377913                         True                           False   \n",
      "377914                        False                            True   \n",
      "377915                         True                           False   \n",
      "\n",
      "        payment_method_WE_BIRR  created_at_period  \n",
      "0                        False            2023-12  \n",
      "1                        False            2024-02  \n",
      "2                        False            2023-12  \n",
      "3                        False            2023-12  \n",
      "4                        False            2023-12  \n",
      "...                        ...                ...  \n",
      "377911                   False            2024-10  \n",
      "377912                   False            2024-10  \n",
      "377913                   False            2024-10  \n",
      "377914                   False            2024-10  \n",
      "377915                   False            2024-10  \n",
      "\n",
      "[377916 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, engine):\n",
    "        self.engine = engine\n",
    "        self.label_encoders = {}\n",
    "\n",
    "    def load_data(self, table_name):\n",
    "        \"\"\"\n",
    "        Load data from the database.\n",
    "        \n",
    "        Args:\n",
    "            table_name (str): Name of the table to load data from.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the loaded data.\n",
    "        \"\"\"\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql(query, self.engine)\n",
    "        return df\n",
    "\n",
    "    def handle_nulls(self, df, strategy='mean'):\n",
    "        \"\"\"\n",
    "        Handle NULL values using the specified strategy.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            strategy (str): Strategy to handle NULLs ('mean', 'median', 'mode', 'constant').\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with NULL values handled.\n",
    "        \"\"\"\n",
    "        if strategy in ['mean', 'median', 'mode']:\n",
    "            numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "            if strategy == 'mean':\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "            elif strategy == 'median':\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "            elif strategy == 'mode':\n",
    "                df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mode().iloc[0])\n",
    "        elif strategy == 'constant':\n",
    "            df = df.fillna(0)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid null strategy. Use 'mean', 'median', 'mode', or 'constant'.\")\n",
    "        return df\n",
    "\n",
    "    def encode_categorical(self, df, columns, encoding_type='onehot'):\n",
    "        \"\"\"\n",
    "        Encode categorical variables using the specified encoding type.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            columns (list): List of categorical columns to encode.\n",
    "            encoding_type (str): Encoding type ('onehot' or 'label').\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with categorical variables encoded.\n",
    "        \"\"\"\n",
    "        if encoding_type == 'onehot':\n",
    "            return pd.get_dummies(df, columns=columns)\n",
    "        elif encoding_type == 'label':\n",
    "            for column in columns:\n",
    "                if column not in self.label_encoders:\n",
    "                    self.label_encoders[column] = LabelEncoder()\n",
    "                    df[column] = self.label_encoders[column].fit_transform(df[column])\n",
    "                else:\n",
    "                    df[column] = self.label_encoders[column].transform(df[column])\n",
    "            return df\n",
    "        else:\n",
    "            raise ValueError(\"Invalid encoding type. Use 'onehot' or 'label'.\")\n",
    "\n",
    "    def aggregate_timestamps(self, df, timestamp_column, period='M'):\n",
    "        \"\"\"\n",
    "        Aggregate timestamps to specified periods.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            timestamp_column (str): Column containing timestamp values.\n",
    "            period (str): Resampling period ('D', 'W', 'M', 'Y').\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame with aggregated timestamps.\n",
    "        \"\"\"\n",
    "        df[timestamp_column] = pd.to_datetime(df[timestamp_column])\n",
    "        df[f'{timestamp_column}_period'] = df[timestamp_column].dt.to_period(period)\n",
    "        return df\n",
    "\n",
    "    def preprocess(self, table_name, null_strategy='mean', categorical_columns=None, encoding_type='onehot', timestamp_column=None, period='M'):\n",
    "        \"\"\"\n",
    "        Preprocess and normalize data for a specific table.\n",
    "        \n",
    "        Parameters:\n",
    "            table_name (str): Name of the database table to preprocess.\n",
    "            null_strategy (str): Strategy to handle NULLs ('mean', 'median', 'mode', 'constant').\n",
    "            categorical_columns (list): List of categorical columns to encode.\n",
    "            encoding_type (str): Encoding type for categorical variables ('onehot' or 'label').\n",
    "            timestamp_column (str): Column containing timestamp values.\n",
    "            period (str): Resampling period for timestamps ('D', 'W', 'M', 'Y').\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Preprocessed DataFrame.\n",
    "        \"\"\"\n",
    "        data = self.load_data(table_name)\n",
    "\n",
    "        # Handle NULL values\n",
    "        data = self.handle_nulls(data, strategy=null_strategy)\n",
    "\n",
    "        # Encode categorical variables\n",
    "        if categorical_columns:\n",
    "            data = self.encode_categorical(data, columns=categorical_columns, encoding_type=encoding_type)\n",
    "\n",
    "        # Aggregate timestamps\n",
    "        if timestamp_column:\n",
    "            data = self.aggregate_timestamps(data, timestamp_column=timestamp_column, period=period)\n",
    "\n",
    "        return data\n",
    "\n",
    "# usage\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessor = DataPreprocessor(engine)\n",
    "\n",
    "    preprocessed_data = preprocessor.preprocess(\n",
    "        table_name='orders',  # Replace with your actual table name\n",
    "        null_strategy='mean',\n",
    "        categorical_columns=['status', 'payment_method'],  # Replace with your actual categorical columns\n",
    "        encoding_type='onehot',\n",
    "        timestamp_column='created_at',  # Replace with your actual timestamp column\n",
    "        period='M'\n",
    "    )\n",
    "    print(preprocessed_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChipChip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
